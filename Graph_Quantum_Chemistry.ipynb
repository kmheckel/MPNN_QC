{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmheckel/MPNN_QC/blob/main/Graph_Quantum_Chemistry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzBEa4pVtZ9C",
        "outputId": "e37a7e35-e740-44ed-a913-14be18ad06c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct version of torch detected. You are running on a machine with GPU.\n"
          ]
        }
      ],
      "source": [
        "#@title [RUN] Sanity check torch version and GPU runtime\n",
        "\n",
        "import torch\n",
        "assert torch.cuda.is_available(), \"WARNING! You are running on a non-GPU instance. For this practical a GPU is highly recommended.\"\n",
        "REQUIRED_VERSION = \"2.1.0+cu121\"\n",
        "TORCH_VERSION = torch.__version__\n",
        "CUDA_VERSION = TORCH_VERSION.split(\"+\")\n",
        "\n",
        "if TORCH_VERSION != REQUIRED_VERSION:\n",
        "  print(f\"Detected torch version {TORCH_VERSION}, but notebook was created for {REQUIRED_VERSION}\")\n",
        "  print(f\"Attempting installation of {REQUIRED_VERSION}\")\n",
        "  !pip install torch==2.1.0+cu121\n",
        "print(\"Correct version of torch detected. You are running on a machine with GPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Install required python libraries\n",
        "import os\n",
        "\n",
        "# Install PyTorch Geometric and other libraries\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    print(\"Installing PyTorch Geometric\")\n",
        "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-geometric\n",
        "    print(\"Installing other libraries\")\n",
        "    !pip install -q rdkit-pypi==2021.9.4\n",
        "    !pip install -q py3Dmol==1.8.0\n",
        "    # !pip install networkx\n",
        "    # !pip install mycolorpy\n",
        "    # !pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QgDyw0ltu7o",
        "outputId": "bed8e087-e28b-4f2e-e12b-1fe2ef4b4b08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PyTorch Geometric\n",
            "Installing other libraries\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: mycolorpy in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mycolorpy) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mycolorpy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mycolorpy) (1.16.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Import python modules\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "from typing import Mapping, Tuple, Sequence, List\n",
        "\n",
        "import pandas as pd\n",
        "# import networkx as nx\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "# from scipy.stats import ortho_group\n",
        "# from scipy.linalg import block_diag\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Embedding, Linear, ReLU, BatchNorm1d, Module, ModuleList, Sequential\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse\n",
        "from torch_geometric.datasets import QM9\n",
        "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
        "from torch_scatter import scatter, scatter_mean, scatter_max, scatter_sum\n",
        "\n",
        "# import rdkit.Chem as Chem\n",
        "# from rdkit.Geometry.rdGeometry import Point3D\n",
        "# from rdkit.Chem import QED, Crippen, rdMolDescriptors, rdmolops\n",
        "# from rdkit.Chem.Draw import IPythonConsole\n",
        "\n",
        "# import py3Dmol\n",
        "# from rdkit.Chem import AllChem\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# from mycolorpy import colorlist as mcp\n",
        "# import matplotlib.cm as cm\n",
        "# import colorama\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import HTML\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"All imports succeeded.\")\n",
        "print(\"Python version {}\".format(sys.version))\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_UDZ_6LtzGU",
        "outputId": "b254d4be-d33e-4af4-b0f2-f505d8dec6ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports succeeded.\n",
            "Python version 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "PyTorch version 2.1.0+cu121\n",
            "PyG version 2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Set random seed for deterministic results\n",
        "\n",
        "def seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed(0)\n",
        "print(\"All seeds set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oQB7rCDt42f",
        "outputId": "8fe62b80-580c-4799-ed1c-ab1657e48c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All seeds set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RESULTS = {}\n",
        "DF_RESULTS = pd.DataFrame(columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])"
      ],
      "metadata": {
        "id": "PJ1GhGm9Sj-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data importing"
      ],
      "metadata": {
        "id": "IxwuHNWFOVzF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QM9(root='/tmp/QM9')"
      ],
      "metadata": {
        "id": "QIEQZtRKt7ss"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = 0\n",
        "dataset.data.y = dataset.data.y[:, target]\n",
        "# Normalize targets per data sample to mean = 0 and std = 1.\n",
        "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
        "std = dataset.data.y.std(dim=0, keepdim=True)\n",
        "dataset.data.y = (dataset.data.y - mean) / std\n",
        "mean, std = mean.item(), std.item()"
      ],
      "metadata": {
        "id": "br03QL4duKfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TO USE FULL DATASET:\n",
        "# test_dataset = dataset[:10000]\n",
        "# val_dataset = dataset[10000:20000]\n",
        "# train_dataset = dataset[20000:]\n",
        "\n",
        "train_dataset = dataset[:1000]\n",
        "val_dataset = dataset[1000:2000]\n",
        "test_dataset = dataset[2000:3000]\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "print(f\"Created dataset splits with {len(train_dataset)} training, {len(val_dataset)} validation, {len(test_dataset)} test samples.\")"
      ],
      "metadata": {
        "id": "JfRX4DhYHu7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Familiarizing with the data"
      ],
      "metadata": {
        "id": "mDugNxzoOYD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_dataset[0]\n",
        "\n",
        "print(f\"\\nThis molecule has {data.x.shape[0]} atoms, and {data.edge_attr.shape[0]} edges.\")\n",
        "\n",
        "print(f\"\\nFor each atom, we are given a feature vector with {data.x.shape[1]} entries (described above).\")\n",
        "\n",
        "print(f\"\\nFor each edge, we are given a feature vector with {data.edge_attr.shape[1]} entries (also described above).\")\n",
        "\n",
        "print(f\"\\nIn the next section, we will learn how to build a GNN in the Message Passing flavor to \\n\\\n",
        "process the node and edge features of molecular graphs and predict their properties.\")\n",
        "\n",
        "print(f\"\\nEach atom also has a {data.pos.shape[1]}-dimensional coordinate associated with it. \\n\\\n",
        "We will talk about their importance later in the practical.\")\n",
        "\n",
        "print(f\"\\nFinally, we have {data.y.shape[0]} regression target for the entire molecule.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVvKbDrLugNQ",
        "outputId": "dab2f572-2b1c-4250-d801-51acf54fa5b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "This molecule has 5 atoms, and 8 edges.\n",
            "\n",
            "For each atom, we are given a feature vector with 11 entries (described above).\n",
            "\n",
            "For each edge, we are given a feature vector with 4 entries (also described above).\n",
            "\n",
            "In the next section, we will learn how to build a GNN in the Message Passing flavor to \n",
            "process the node and edge features of molecular graphs and predict their properties.\n",
            "\n",
            "Each atom also has a 3-dimensional coordinate associated with it. \n",
            "We will talk about their importance later in the practical.\n",
            "\n",
            "Finally, we have 1 regression target for the entire molecule.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Helper functions for managing experiments, training, and evaluating models.\n",
        "\n",
        "def train(model, train_loader, optimizer, device):\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(data)\n",
        "        loss = F.mse_loss(y_pred, data.y)\n",
        "        loss.backward()\n",
        "        loss_all += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_loader.dataset)\n",
        "\n",
        "\n",
        "def eval(model, loader, device):\n",
        "    model.eval()\n",
        "    error = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(data)\n",
        "            # Mean Absolute Error using std (computed when preparing data)\n",
        "            error += (y_pred * std - data.y * std).abs().sum().item()\n",
        "    return error / len(loader.dataset)\n",
        "\n",
        "\n",
        "def run_experiment(model, model_name, train_loader, val_loader, test_loader, n_epochs=100, patience=float('inf')):\n",
        "    print(f\"Running experiment for {model_name}, training on {len(train_loader.dataset)} samples for {n_epochs} epochs.\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Training on {device}.')\n",
        "\n",
        "    print(\"\\nModel architecture:\")\n",
        "    print(model)\n",
        "    total_param = 0\n",
        "    for param in model.parameters():\n",
        "        total_param += np.prod(list(param.data.size()))\n",
        "    print(f'Total parameters: {total_param}')\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=5, min_lr=0.00001)\n",
        "\n",
        "    print(\"\\nStart training:\")\n",
        "    best_val_error = float('inf')\n",
        "    perf_per_epoch = []\n",
        "    t = time.time()\n",
        "    patience_counter = 0\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "        loss = train(model, train_loader, optimizer, device)\n",
        "        val_error = eval(model, val_loader, device)\n",
        "\n",
        "        if val_error < best_val_error:\n",
        "            best_val_error = val_error\n",
        "            test_error = eval(model, test_loader, device)  # Evaluate model on test set if validation metric improves\n",
        "            patience_counter = 0  # Reset patience counter\n",
        "\n",
        "            # Generate the current date string\n",
        "            current_date = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
        "            model_save_path = f'models/{current_date}/{model_name}_{model.num_layers}layers_{type(model.aggr).__name__}_aggr.pt'\n",
        "\n",
        "            # Create directory if it does not exist\n",
        "            os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
        "\n",
        "            # Save the model\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch: {epoch:03d}, LR: {lr:5f}, Loss: {loss:.7f}, '\n",
        "                  f'Val MAE: {val_error:.7f}, Test MAE: {test_error:.7f}')\n",
        "\n",
        "        scheduler.step(val_error)\n",
        "        perf_per_epoch.append((test_error, val_error, epoch, model_name))\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early due to no improvement in validation loss for {patience} epochs.\")\n",
        "            break\n",
        "\n",
        "    t = time.time() - t\n",
        "    train_time = t / 60\n",
        "    print(f\"\\nDone! Training took {train_time:.2f} mins. Best validation MAE: {best_val_error:.7f}, corresponding test MAE: {test_error:.7f}.\")\n",
        "\n",
        "    return best_val_error, test_error, train_time, perf_per_epoch"
      ],
      "metadata": {
        "id": "jPayO0nQNrvs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example usage"
      ],
      "metadata": {
        "id": "2YVygNniOhu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCNConv, GINConv, global_mean_pool, GRUAggregation, Set2Set\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class CustomGNN(torch.nn.Module):\n",
        "    def __init__(self, input_channels, hidden_channels, output_channels=1, num_layers=4, T=4):\n",
        "        super(CustomGNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.first_layer = Linear(input_channels, hidden_channels)\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        # Hidden layers\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GCNConv(hidden_channels, hidden_channels))\n",
        "\n",
        "        # if not using set2set\n",
        "        # self.out = torch.nn.Linear(hidden_channels, output_channels)\n",
        "\n",
        "        self.out = torch.nn.Linear(2 * hidden_channels, output_channels)\n",
        "        self.aggr = Set2Set(in_channels=hidden_channels, processing_steps=T)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = self.first_layer(data.x)\n",
        "        for conv in self.convs:\n",
        "            x = x + F.relu(conv(x, data.edge_index))\n",
        "        # x = global_mean_pool(x, data.batch)\n",
        "        x = self.aggr(x, data.batch)\n",
        "        x = self.out(x)\n",
        "        return x.view(-1)"
      ],
      "metadata": {
        "id": "PnrRlQk0awrE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 5\n",
        "\n",
        "model = CustomGNN(dataset.num_node_features, hidden_channels=64, num_layers=num_layers)\n",
        "model_name = type(model).__name__\n",
        "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
        "    model,\n",
        "    model_name,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    test_loader,\n",
        "    n_epochs=100\n",
        ")\n",
        "RESULTS[model_name] = (best_val_error, test_error, train_time)\n",
        "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])\n",
        "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
      ],
      "metadata": {
        "id": "78lYJlgiOjJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "RESULTS"
      ],
      "metadata": {
        "id": "ABKm2YOfOyTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = sns.lineplot(x=\"Epoch\", y=\"Val MAE\", hue=\"Model\", data=DF_RESULTS)\n",
        "p.set(ylim=(0, 2));"
      ],
      "metadata": {
        "id": "R-7Tac4qOrfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p = sns.lineplot(x=\"Epoch\", y=\"Test MAE\", hue=\"Model\", data=DF_RESULTS)\n",
        "p.set(ylim=(0, 1));"
      ],
      "metadata": {
        "id": "p3kNjZIZOzX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example of how to create a GNN from zero that uses pos encoding\n",
        "# We don't need this yet!"
      ],
      "metadata": {
        "id": "hh7rluy_O0YZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EquivariantMPNNLayer(MessagePassing):\n",
        "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
        "        \"\"\"Message Passing Neural Network Layer\n",
        "\n",
        "        This layer is equivariant to 3D rotations and translations.\n",
        "\n",
        "        Args:\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
        "        \"\"\"\n",
        "        # Set the aggregation function\n",
        "        super().__init__(aggr=aggr)\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.edge_dim = edge_dim\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Define the MLPs constituting your new layer.\n",
        "        # At the least, you will need `\\psi` and `\\phi`\n",
        "        # (but their definitions may be different from what\n",
        "        # we used previously).\n",
        "        #\n",
        "        # self.mlp_msg = ...  # MLP `\\psi`\n",
        "\n",
        "        # MLP `\\psi` for computing messages `m_ij`\n",
        "        # dims: d -> 1\n",
        "        # self.mlp_pos = ...\n",
        "\n",
        "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
        "        # dims: 2d -> d\n",
        "        # self.mlp_upd = ...\n",
        "        # ===========================================\n",
        "        self.mlp_msg = Sequential(\n",
        "            Linear(2*emb_dim + edge_dim +1, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "\n",
        "        self.mlp_pos = Sequential(\n",
        "             Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim),  ReLU(), Linear(emb_dim, 1))\n",
        "\n",
        "\n",
        "        self.mlp_upd = Sequential(\n",
        "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "\n",
        "    def forward(self, h, pos, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        The forward pass updates node features `h` via one round of message passing.\n",
        "\n",
        "        Args:\n",
        "            h: (n, d) - initial node features\n",
        "            pos: (n, 3) - initial node coordinates\n",
        "            edge_index: (e, 2) - pairs of edges (i, j)\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "\n",
        "        Returns:\n",
        "            out: [(n, d),(n,3)] - updated node features\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Notice that the `forward()` function has a new argument\n",
        "        # `pos` denoting the initial node coordinates. Your task is\n",
        "        # to update the `propagate()` function in order to pass `pos`\n",
        "        # to the `message()` function along with the other arguments.\n",
        "        #\n",
        "        # out = self.propagate(...)\n",
        "        # return out\n",
        "        # ==========================================\n",
        "        out = self.propagate(edge_index, h=h, edge_attr=edge_attr,pos=pos)\n",
        "        return out\n",
        "\n",
        "    # ============ YOUR CODE HERE ==============\n",
        "    # Write custom `message()`, `aggregate()`, and `update()` functions\n",
        "    # which ensure that the layer is 3D rotation and translation equivariant.\n",
        "    #\n",
        "    # def message(self, ...):\n",
        "    #   ...\n",
        "    #\n",
        "    # def aggregate(self, ...):\n",
        "    #   ...\n",
        "    #\n",
        "    # def update(self, ...):\n",
        "    #   ...\n",
        "    #\n",
        "    # ==========================================\n",
        "\n",
        "    def message(self, h_i, h_j, pos, edge_index,edge_attr):\n",
        "        pos_i = pos[edge_index[1]]\n",
        "        pos_j = pos[edge_index[0]]\n",
        "        rel_pos = pos_i - pos_j\n",
        "        rel_pos_norm = (torch.norm(rel_pos, 2, dim=-1)**2)\n",
        "        rel_pos_norm = torch.atleast_2d(rel_pos_norm).T\n",
        "        msg = torch.cat([h_i, h_j, edge_attr, rel_pos_norm], dim=-1)\n",
        "        msg = self.mlp_msg(msg)\n",
        "\n",
        "        rel_pos = rel_pos * self.mlp_pos(msg)\n",
        "\n",
        "        return msg, rel_pos\n",
        "\n",
        "    def aggregate(self, inputs, index):\n",
        "        msg, rel_pos = inputs\n",
        "        aggr_msg = scatter(msg, index, dim=self.node_dim, reduce=self.aggr)\n",
        "        aggr_pos = scatter(rel_pos, index, dim=self.node_dim, reduce=self.aggr)\n",
        "        return aggr_msg, aggr_pos\n",
        "\n",
        "    def update(self, inputs, h, pos):\n",
        "      aggr_msg, aggr_pos = inputs\n",
        "      upd_out = torch.cat([h, aggr_msg], dim=-1)\n",
        "      upd_pos = pos + aggr_pos\n",
        "      return self.mlp_upd(upd_out), upd_pos\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n",
        "\n",
        "class FinalMPNNModel(MPNNModel):\n",
        "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n",
        "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
        "\n",
        "        This model uses both node features and coordinates as inputs, and\n",
        "        is invariant to 3D rotations and translations (the constituent MPNN layers\n",
        "        are equivariant to 3D rotations and translations).\n",
        "\n",
        "        Args:\n",
        "            num_layers: (int) - number of message passing layers `L`\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            in_dim: (int) - initial node feature dimension `d_n`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            out_dim: (int) - output dimension (fixed to 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Linear projection for initial node features\n",
        "        # dim: d_n -> d\n",
        "        self.lin_in = Linear(in_dim, emb_dim)\n",
        "\n",
        "        # Stack of MPNN layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.convs.append(EquivariantMPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
        "\n",
        "        # Global pooling/readout function `R` (mean pooling)\n",
        "        # PyG handles the underlying logic via `global_mean_pool()`\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Linear prediction head\n",
        "        # dim: d -> out_dim\n",
        "        self.lin_pred = Linear(emb_dim, out_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: (PyG.Data) - batch of PyG graphs\n",
        "\n",
        "        Returns:\n",
        "            out: (batch_size, out_dim) - prediction for each graph\n",
        "        \"\"\"\n",
        "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
        "        pos = data.pos\n",
        "\n",
        "        for conv in self.convs:\n",
        "            # Message passing layer\n",
        "            h_update, pos_update = conv(h, pos, data.edge_index, data.edge_attr)\n",
        "\n",
        "            # Update node features\n",
        "            h = h + h_update # (n, d) -> (n, d)\n",
        "            # Note that we add a residual connection after each MPNN layer\n",
        "\n",
        "            # Update node coordinates\n",
        "            pos = pos_update # (n, 3) -> (n, 3)\n",
        "\n",
        "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
        "\n",
        "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
        "\n",
        "        return out.view(-1)"
      ],
      "metadata": {
        "id": "3LCsBeLkXwet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m3PZ3ZGJdWMd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}