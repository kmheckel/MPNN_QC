{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOERaUhCVpaIfvXawaXCKA+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmheckel/MPNN_QC/blob/main/Graph_Quantum_Chemistry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzBEa4pVtZ9C",
        "outputId": "e37a7e35-e740-44ed-a913-14be18ad06c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct version of torch detected. You are running on a machine with GPU.\n"
          ]
        }
      ],
      "source": [
        "#@title [RUN] Sanity check torch version and GPU runtime\n",
        "\n",
        "import torch\n",
        "assert torch.cuda.is_available(), \"WARNING! You are running on a non-GPU instance. For this practical a GPU is highly recommended.\"\n",
        "REQUIRED_VERSION = \"2.1.0+cu121\"\n",
        "TORCH_VERSION = torch.__version__\n",
        "CUDA_VERSION = TORCH_VERSION.split(\"+\")\n",
        "\n",
        "if TORCH_VERSION != REQUIRED_VERSION:\n",
        "  print(f\"Detected torch version {TORCH_VERSION}, but notebook was created for {REQUIRED_VERSION}\")\n",
        "  print(f\"Attempting installation of {REQUIRED_VERSION}\")\n",
        "  !pip install torch==2.1.0+cu121\n",
        "print(\"Correct version of torch detected. You are running on a machine with GPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Install required python libraries\n",
        "import os\n",
        "\n",
        "# Install PyTorch Geometric and other libraries\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    print(\"Installing PyTorch Geometric\")\n",
        "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-geometric\n",
        "    print(\"Installing other libraries\")\n",
        "    !pip install -q rdkit-pypi==2021.9.4\n",
        "    !pip install -q py3Dmol==1.8.0\n",
        "    !pip install networkx\n",
        "    !pip install mycolorpy\n",
        "    !pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QgDyw0ltu7o",
        "outputId": "bed8e087-e28b-4f2e-e12b-1fe2ef4b4b08"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PyTorch Geometric\n",
            "Installing other libraries\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: mycolorpy in /usr/local/lib/python3.10/dist-packages (1.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mycolorpy) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mycolorpy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mycolorpy) (1.16.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Import python modules\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "from typing import Mapping, Tuple, Sequence, List\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.stats import ortho_group\n",
        "from scipy.linalg import block_diag\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Embedding, Linear, ReLU, BatchNorm1d, Module, ModuleList, Sequential\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse\n",
        "from torch_geometric.datasets import Planetoid, QM9\n",
        "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
        "from torch_scatter import scatter, scatter_mean, scatter_max, scatter_sum\n",
        "\n",
        "import rdkit.Chem as Chem\n",
        "from rdkit.Geometry.rdGeometry import Point3D\n",
        "from rdkit.Chem import QED, Crippen, rdMolDescriptors, rdmolops\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "\n",
        "import py3Dmol\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mycolorpy import colorlist as mcp\n",
        "import matplotlib.cm as cm\n",
        "import colorama\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import HTML\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"All imports succeeded.\")\n",
        "print(\"Python version {}\".format(sys.version))\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_UDZ_6LtzGU",
        "outputId": "b254d4be-d33e-4af4-b0f2-f505d8dec6ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports succeeded.\n",
            "Python version 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "PyTorch version 2.1.0+cu121\n",
            "PyG version 2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Set random seed for deterministic results\n",
        "\n",
        "def seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed(0)\n",
        "print(\"All seeds set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oQB7rCDt42f",
        "outputId": "8fe62b80-580c-4799-ed1c-ab1657e48c86"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All seeds set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Helper functions for data preparation\n",
        "\n",
        "class SetTarget:\n",
        "    \"\"\"\n",
        "    This transform modifies the labels vector per data sample to only keep\n",
        "    the label for a specific target (there are 19 targets in QM9).\n",
        "\n",
        "    Note: for this practical, we have hardcoded the target to be target #0,\n",
        "    i.e. the electric dipole moment of a drug-like molecule.\n",
        "    (https://en.wikipedia.org/wiki/Electric_dipole_moment)\n",
        "    \"\"\"\n",
        "    def __init__(self, target=0):\n",
        "      self.target = target\n",
        "    def __call__(self, data):\n",
        "        data.y = data.y[:, self.target]\n",
        "        return data\n",
        "\n",
        "\n",
        "class CompleteGraph:\n",
        "    \"\"\"\n",
        "    This transform adds all pairwise edges into the edge index per data sample,\n",
        "    then removes self loops, i.e. it builds a fully connected or complete graph\n",
        "    \"\"\"\n",
        "    def __call__(self, input):\n",
        "        data = input.clone()\n",
        "        device = data.edge_index.device\n",
        "\n",
        "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "\n",
        "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
        "        col = col.repeat(data.num_nodes)\n",
        "        edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "        edge_attr = None\n",
        "        if data.edge_attr is not None:\n",
        "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
        "            size = list(data.edge_attr.size())\n",
        "            size[0] = data.num_nodes * data.num_nodes\n",
        "            edge_attr = data.edge_attr.new_zeros(size)\n",
        "            edge_attr[idx] = data.edge_attr\n",
        "\n",
        "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
        "        data.edge_attr = edge_attr\n",
        "        data.edge_index = edge_index\n",
        "\n",
        "        return data\n",
        "\n",
        "print(\"Helper functions loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D53xaR6SuPVb",
        "outputId": "6fd3446b-71c3-4c51-d83c-d65a3f255a47"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Helper functions for plots and visualisations\n",
        "\n",
        "\n",
        "def draw_one_graph(ax, edges, label=None, node_emb=None, layout=None, special_color=False):\n",
        "    \"\"\"draw a graph with networkx based on adjacency matrix (edges)\n",
        "    graph labels could be displayed as a title for each graph\n",
        "    node_emb could be displayed in colors\n",
        "    \"\"\"\n",
        "    graph = nx.Graph()\n",
        "    edges = zip(edges[0], edges[1])\n",
        "    graph.add_edges_from(edges)\n",
        "    node_pos = layout(graph)\n",
        "    #add colors according to node embeding\n",
        "    if (node_emb is not None) or special_color:\n",
        "        color_map = []\n",
        "        node_list = [node[0] for node in graph.nodes(data = True)]\n",
        "        for i,node in enumerate(node_list):\n",
        "            #just ignore this branch\n",
        "            if special_color:\n",
        "                if len(node_list) == 3:\n",
        "                    crt_color = (1,0,0)\n",
        "                elif len(node_list) == 5:\n",
        "                    crt_color = (0,1,0)\n",
        "                elif len(node_list) == 4:\n",
        "                    crt_color = (1,1,0)\n",
        "                else:\n",
        "                  special_list = [(1,0,0)] * 3 + [(0,1,0)] * 5 + [(1,1,0)] * 4\n",
        "                  crt_color = special_list[i]\n",
        "            else:\n",
        "                crt_node_emb = node_emb[node]\n",
        "                #map float number (node embeding) to a color\n",
        "                crt_color = cm.gist_rainbow(crt_node_emb, bytes=True)\n",
        "                crt_color = (crt_color[0]/255.0, crt_color[1]/255.0, crt_color[2]/255.0, crt_color[3]/255.0)\n",
        "            color_map.append(crt_color)\n",
        "\n",
        "        nx.draw_networkx_nodes(graph,node_pos, node_color=color_map,\n",
        "                        nodelist = node_list, ax=ax)\n",
        "        nx.draw_networkx_edges(graph, node_pos, ax=ax)\n",
        "        nx.draw_networkx_labels(graph,node_pos, ax=ax)\n",
        "    else:\n",
        "        nx.draw_networkx(graph, node_pos, ax=ax)\n",
        "\n",
        "\n",
        "def gallery(graphs, labels=None, node_emb=None, special_color=False, max_graphs=4, max_fig_size=(40, 10), layout=nx.layout.kamada_kawai_layout):\n",
        "    ''' Draw multiple graphs as a gallery\n",
        "    Args:\n",
        "      graphs: torch_geometrics.dataset object/ List of Graph objects\n",
        "      labels: num_graphs\n",
        "      node_emb: num_graphs* [num_nodes x num_ch]\n",
        "      max_graphs: maximum graphs display\n",
        "    '''\n",
        "    num_graphs = min(len(graphs), max_graphs)\n",
        "    ff, axes = plt.subplots(1, num_graphs,\n",
        "                            figsize=max_fig_size,\n",
        "                            subplot_kw={'xticks': [], 'yticks': []})\n",
        "    if num_graphs == 1:\n",
        "        axes = [axes]\n",
        "    if node_emb is None:\n",
        "        node_emb = num_graphs*[None]\n",
        "    if labels is None:\n",
        "        labels = num_graphs * [\" \"]\n",
        "\n",
        "\n",
        "    for i in range(num_graphs):\n",
        "        draw_one_graph(axes[i], graphs[i].edge_index.numpy(), labels[i], node_emb[i], layout, special_color)\n",
        "        if labels[i] != \" \":\n",
        "            axes[i].set_title(f\"Target: {labels[i]}\", fontsize=28)\n",
        "        axes[i].set_axis_off()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def hash_node_embedings(node_emb):\n",
        "  \"\"\" Hash the tensor representing nodes' features\n",
        "  to a number in [0,1] used to represent a color\n",
        "\n",
        "  Args:\n",
        "    node_emb: list of num_graphs arrays, each of dim (num_nodes x num_feats)\n",
        "  Returns:\n",
        "    list of num_graphs arrays in [0,1], each of dim (num_nodes)\n",
        "  \"\"\"\n",
        "  chunk_size_graph = [x.shape[0] for x in node_emb]\n",
        "  start_idx_graph = [0] + list(itertools.accumulate(chunk_size_graph))[:-1]\n",
        "\n",
        "  node_emb_flatten = np.concatenate(node_emb).mean(-1)\n",
        "\n",
        "  min_emb = node_emb_flatten.min()\n",
        "  max_emb = node_emb_flatten.max()\n",
        "  node_emb_flatten = (node_emb_flatten-min_emb)/(max_emb-min_emb)\n",
        "\n",
        "  #split in graphs again according to (start_idx_graph, chunk_size_graph)\n",
        "  node_emb_hashed = [node_emb_flatten[i:i+l] for (i,l) in zip(start_idx_graph, chunk_size_graph)]\n",
        "  return node_emb_hashed\n",
        "\n",
        "\n",
        "def update_stats(training_stats, epoch_stats):\n",
        "    \"\"\" Store metrics along the training\n",
        "    Args:\n",
        "      epoch_stats: dict containg metrics about one epoch\n",
        "      training_stats: dict containing lists of metrics along training\n",
        "    Returns:\n",
        "      updated training_stats\n",
        "    \"\"\"\n",
        "    if training_stats is None:\n",
        "        training_stats = {}\n",
        "        for key in epoch_stats.keys():\n",
        "            training_stats[key] = []\n",
        "    for key,val in epoch_stats.items():\n",
        "        training_stats[key].append(val)\n",
        "    return training_stats\n",
        "\n",
        "\n",
        "def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n",
        "    \"\"\" Create one plot for each metric stored in training_stats\n",
        "    \"\"\"\n",
        "    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n",
        "    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n",
        "    if len(stats_names)==1:\n",
        "        ax = np.array([ax])\n",
        "    for key, axx in zip(stats_names, ax.reshape(-1,)):\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'train_{key}'],\n",
        "            label=f\"Training {key}\")\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'val_{key}'],\n",
        "            label=f\"Validation {key}\")\n",
        "        axx.set_xlabel(\"Training epoch\")\n",
        "        axx.set_ylabel(key)\n",
        "        axx.legend()\n",
        "    plt.title(name)\n",
        "\n",
        "\n",
        "def get_color_coded_str(i, color):\n",
        "    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n",
        "\n",
        "\n",
        "def print_color_numpy(map, list_graphs):\n",
        "    \"\"\" print matrix map in color according to list_graphs\n",
        "    \"\"\"\n",
        "    list_blocks = []\n",
        "    for i,graph in enumerate(list_graphs):\n",
        "        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n",
        "        list_blocks += [block_i]\n",
        "    block_color = block_diag(*list_blocks)\n",
        "\n",
        "    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n",
        "    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))\n",
        "\n",
        "\n",
        "#############################################\n",
        "# Visualization helpers for molecular graphs\n",
        "#############################################\n",
        "\n",
        "allowable_atoms = [\n",
        "    \"H\",\n",
        "    \"C\",\n",
        "    \"N\",\n",
        "    \"O\",\n",
        "    \"F\",\n",
        "    \"C\",\n",
        "    \"Cl\",\n",
        "    \"Br\",\n",
        "    \"I\",\n",
        "    \"H\",\n",
        "    \"Unknown\",\n",
        "]\n",
        "\n",
        "def to_atom(t):\n",
        "    try:\n",
        "        return allowable_atoms[int(t.argmax())]\n",
        "    except:\n",
        "        return \"C\"\n",
        "\n",
        "\n",
        "def to_bond_index(t):\n",
        "    t_s = t.squeeze()\n",
        "    return [1, 2, 3, 4][\n",
        "        int(\n",
        "            torch.dot(\n",
        "                t_s,\n",
        "                torch.tensor(\n",
        "                    range(t_s.size()[0]), dtype=torch.float, device=t.device\n",
        "                ),\n",
        "            ).item()\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def to_rdkit(data, device=None):\n",
        "    has_pos = False\n",
        "    node_list = []\n",
        "    for i in range(data.x.size()[0]):\n",
        "        node_list.append(to_atom(data.x[i][:5]))\n",
        "\n",
        "    # create empty editable mol object\n",
        "    mol = Chem.RWMol()\n",
        "    # add atoms to mol and keep track of index\n",
        "    node_to_idx = {}\n",
        "    invalid_idx = set([])\n",
        "    for i in range(len(node_list)):\n",
        "        if node_list[i] == \"Stop\" or node_list[i] == \"H\":\n",
        "            invalid_idx.add(i)\n",
        "            continue\n",
        "        a = Chem.Atom(node_list[i])\n",
        "        molIdx = mol.AddAtom(a)\n",
        "        node_to_idx[i] = molIdx\n",
        "\n",
        "    added_bonds = set([])\n",
        "    for i in range(0, data.edge_index.size()[1]):\n",
        "        ix = data.edge_index[0][i].item()\n",
        "        iy = data.edge_index[1][i].item()\n",
        "        bond = to_bond_index(data.edge_attr[i])  # <font color='red'>TODO</font> fix this\n",
        "        # bond = 1\n",
        "        # add bonds between adjacent atoms\n",
        "\n",
        "        if data.edge_attr[i].sum() == 0:\n",
        "          continue\n",
        "\n",
        "        if (\n",
        "            (str((ix, iy)) in added_bonds)\n",
        "            or (str((iy, ix)) in added_bonds)\n",
        "            or (iy in invalid_idx or ix in invalid_idx)\n",
        "        ):\n",
        "            continue\n",
        "        # add relevant bond type (there are many more of these)\n",
        "\n",
        "        if bond == 0:\n",
        "            continue\n",
        "        elif bond == 1:\n",
        "            bond_type = Chem.rdchem.BondType.SINGLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 2:\n",
        "            bond_type = Chem.rdchem.BondType.DOUBLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 3:\n",
        "            bond_type = Chem.rdchem.BondType.TRIPLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 4:\n",
        "            bond_type = Chem.rdchem.BondType.SINGLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "\n",
        "        added_bonds.add(str((ix, iy)))\n",
        "\n",
        "    if has_pos:\n",
        "        conf = Chem.Conformer(mol.GetNumAtoms())\n",
        "        for i in range(data.pos.size(0)):\n",
        "            if i in invalid_idx:\n",
        "                continue\n",
        "            p = Point3D(\n",
        "                data.pos[i][0].item(),\n",
        "                data.pos[i][1].item(),\n",
        "                data.pos[i][2].item(),\n",
        "            )\n",
        "            conf.SetAtomPosition(node_to_idx[i], p)\n",
        "        conf.SetId(0)\n",
        "        mol.AddConformer(conf)\n",
        "\n",
        "    # Convert RWMol to Mol object\n",
        "    mol = mol.GetMol()\n",
        "    mol_frags = rdmolops.GetMolFrags(mol, asMols=True, sanitizeFrags=False)\n",
        "    largest_mol = max(mol_frags, default=mol, key=lambda m: m.GetNumAtoms())\n",
        "    return largest_mol\n",
        "\n",
        "\n",
        "def MolTo3DView(mol, size=(300, 300), style=\"stick\", surface=False, opacity=0.5):\n",
        "    \"\"\"Draw molecule in 3D\n",
        "\n",
        "    Args:\n",
        "    ----\n",
        "        mol: rdMol, molecule to show\n",
        "        size: tuple(int, int), canvas size\n",
        "        style: str, type of drawing molecule\n",
        "               style can be 'line', 'stick', 'sphere', 'carton'\n",
        "        surface, bool, display SAS\n",
        "        opacity, float, opacity of surface, range 0.0-1.0\n",
        "    Return:\n",
        "    ----\n",
        "        viewer: py3Dmol.view, a class for constructing embedded 3Dmol.js views in ipython notebooks.\n",
        "    \"\"\"\n",
        "    assert style in ('line', 'stick', 'sphere', 'carton')\n",
        "\n",
        "    mol = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(mol)\n",
        "    AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
        "    mblock = Chem.MolToMolBlock(mol)\n",
        "    viewer = py3Dmol.view(width=size[0], height=size[1])\n",
        "    viewer.addModel(mblock, 'mol')\n",
        "    viewer.setStyle({style:{}})\n",
        "    if surface:\n",
        "        viewer.addSurface(py3Dmol.SAS, {'opacity': opacity})\n",
        "    viewer.zoomTo()\n",
        "    return viewer\n",
        "\n",
        "def smi2conf(smiles):\n",
        "    '''Convert SMILES to rdkit.Mol with 3D coordinates'''\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        mol = Chem.AddHs(mol)\n",
        "        AllChem.EmbedMolecule(mol)\n",
        "        AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
        "        return mol\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "print(\"Helper functions loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdAPY5jDuW3L",
        "outputId": "09d1a61b-8ace-4a38-957e-64d7715aa635"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    path = './qm9'\n",
        "    target = 0\n",
        "\n",
        "    # Transforms which are applied during data loading:\n",
        "    # Select the target/label\n",
        "    transform = T.Compose([SetTarget(target=target)])\n",
        "\n",
        "    # Load the QM9 dataset with the transforms defined\n",
        "    # dataset = QM9(path, transform=transform)\n",
        "    dataset = QM9(path)\n",
        "\n",
        "    # Normalize targets per data sample to mean = 0 and std = 1.\n",
        "    mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
        "    std = dataset.data.y.std(dim=0, keepdim=True)\n",
        "    # dataset.data.y = (dataset.data.y - mean) / std\n",
        "    mean, std = mean[:, target].item(), std[:, target].item()"
      ],
      "metadata": {
        "id": "QIEQZtRKt7ss"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total number of samples: {len(dataset)}.\")\n",
        "\n",
        "# Split datasets (in case of using the full dataset)\n",
        "# test_dataset = dataset[:10000]\n",
        "# val_dataset = dataset[10000:20000]\n",
        "# train_dataset = dataset[20000:]\n",
        "\n",
        "# Split datasets (our 3K subset)\n",
        "train_pyg_dataset = dataset[:1000]\n",
        "val_pyg_dataset = dataset[1000:2000]\n",
        "test_pyg_dataset = dataset[2000:3000]\n",
        "print(f\"Created dataset splits with {len(train_pyg_dataset)} training, {len(val_pyg_dataset)} validation, {len(test_pyg_dataset)} test samples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "br03QL4duKfs",
        "outputId": "443fb26b-99a2-4238-f68d-0fc1789d2805"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of samples: 130831.\n",
            "Created dataset splits with 1000 training, 1000 validation, 1000 test samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_pyg_dataset[0]\n",
        "\n",
        "print(f\"\\nThis molecule has {data.x.shape[0]} atoms, and {data.edge_attr.shape[0]} edges.\")\n",
        "\n",
        "print(f\"\\nFor each atom, we are given a feature vector with {data.x.shape[1]} entries (described above).\")\n",
        "\n",
        "print(f\"\\nFor each edge, we are given a feature vector with {data.edge_attr.shape[1]} entries (also described above).\")\n",
        "\n",
        "print(f\"\\nIn the next section, we will learn how to build a GNN in the Message Passing flavor to \\n\\\n",
        "process the node and edge features of molecular graphs and predict their properties.\")\n",
        "\n",
        "print(f\"\\nEach atom also has a {data.pos.shape[1]}-dimensional coordinate associated with it. \\n\\\n",
        "We will talk about their importance later in the practical.\")\n",
        "\n",
        "print(f\"\\nFinally, we have {data.y.shape[0]} regression target for the entire molecule.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVvKbDrLugNQ",
        "outputId": "dab2f572-2b1c-4250-d801-51acf54fa5b6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "This molecule has 5 atoms, and 8 edges.\n",
            "\n",
            "For each atom, we are given a feature vector with 11 entries (described above).\n",
            "\n",
            "For each edge, we are given a feature vector with 4 entries (also described above).\n",
            "\n",
            "In the next section, we will learn how to build a GNN in the Message Passing flavor to \n",
            "process the node and edge features of molecular graphs and predict their properties.\n",
            "\n",
            "Each atom also has a 3-dimensional coordinate associated with it. \n",
            "We will talk about their importance later in the practical.\n",
            "\n",
            "Finally, we have 1 regression target for the entire molecule.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataloaders with batch size = 32\n",
        "train_loader = DataLoader(train_pyg_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_pyg_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_pyg_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "a6TqIpxOvbTa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = train_pyg_dataset[1]\n",
        "data.y, data.x, data.pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEVBbIb8vd5k",
        "outputId": "126fa8e1-ddc1-4626-e7cb-05c782d7f85f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 1.6256e+00,  9.4600e+00, -6.9933e+00,  2.2558e+00,  9.2491e+00,\n",
              "           2.6156e+01,  9.3493e-01, -1.5381e+03, -1.5381e+03, -1.5380e+03,\n",
              "          -1.5387e+03,  6.3160e+00, -1.2006e+01, -1.2082e+01, -1.2159e+01,\n",
              "          -1.1246e+01,  2.9361e+02,  2.9354e+02,  1.9139e+02]]),\n",
              " tensor([[0., 0., 1., 0., 0., 7., 0., 0., 0., 0., 3.],\n",
              "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "         [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]),\n",
              " tensor([[-0.0404,  1.0241,  0.0626],\n",
              "         [ 0.0173,  0.0125, -0.0274],\n",
              "         [ 0.9158,  1.3587, -0.0288],\n",
              "         [-0.5203,  1.3435, -0.7755]]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pm9a71msxiWT",
        "outputId": "1776c22a-a176-44e4-91e9-7a6b051130c2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 19])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MPNNModel(Module):\n",
        "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n",
        "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
        "\n",
        "        Args:\n",
        "            num_layers: (int) - number of message passing layers `L`\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            in_dim: (int) - initial node feature dimension `d_n`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            out_dim: (int) - output dimension (fixed to 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Linear projection for initial node features\n",
        "        # dim: d_n -> d\n",
        "        self.lin_in = Linear(in_dim, emb_dim)\n",
        "\n",
        "        # Stack of MPNN layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.convs.append(MPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
        "\n",
        "        # Global pooling/readout function `R` (mean pooling)\n",
        "        # PyG handles the underlying logic via `global_mean_pool()`\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Linear prediction head\n",
        "        # dim: d -> out_dim\n",
        "        self.lin_pred = Linear(emb_dim, out_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: (PyG.Data) - batch of PyG graphs\n",
        "\n",
        "        Returns:\n",
        "            out: (batch_size, out_dim) - prediction for each graph\n",
        "        \"\"\"\n",
        "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
        "\n",
        "        for conv in self.convs:\n",
        "            h = h + conv(h, data.edge_index, data.edge_attr) # (n, d) -> (n, d)\n",
        "            # Note that we add a residual connection after each MPNN layer\n",
        "\n",
        "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
        "\n",
        "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
        "\n",
        "        return out.view(-1)\n",
        "\n",
        "class InvariantMPNNLayer(MessagePassing):\n",
        "    def __init__(self, emb_dim=64, edge_dim=4, aggr='add'):\n",
        "        \"\"\"Message Passing Neural Network Layer\n",
        "\n",
        "        This layer is invariant to 3D rotations and translations.\n",
        "\n",
        "        Args:\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            aggr: (str) - aggregation function `\\oplus` (sum/mean/max)\n",
        "        \"\"\"\n",
        "        # Set the aggregation function\n",
        "        super().__init__(aggr=aggr)\n",
        "\n",
        "        self.emb_dim = emb_dim\n",
        "        self.edge_dim = edge_dim\n",
        "\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # MLP `\\psi` for computing messages `m_ij`\n",
        "        # dims: (2d + d_e) -> d\n",
        "        self.mlp_msg = Sequential(\n",
        "            Linear(2*emb_dim + edge_dim + 1, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "        # ==========================================\n",
        "\n",
        "        # MLP `\\phi` for computing updated node features `h_i^{l+1}`\n",
        "        # dims: 2d -> d\n",
        "        self.mlp_upd = Sequential(\n",
        "            Linear(2*emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU(),\n",
        "            Linear(emb_dim, emb_dim), BatchNorm1d(emb_dim), ReLU()\n",
        "          )\n",
        "\n",
        "    def forward(self, h, pos, edge_index, edge_attr):\n",
        "        \"\"\"\n",
        "        The forward pass updates node features `h` via one round of message passing.\n",
        "\n",
        "        Args:\n",
        "            h: (n, d) - initial node features\n",
        "            pos: (n, 3) - initial node coordinates\n",
        "            edge_index: (e, 2) - pairs of edges (i, j)\n",
        "            edge_attr: (e, d_e) - edge features\n",
        "\n",
        "        Returns:\n",
        "            out: (n, d) - updated node features\n",
        "        \"\"\"\n",
        "        # ============ YOUR CODE HERE ==============\n",
        "        # Notice that the `forward()` function has a new argument\n",
        "        # `pos` denoting the initial node coordinates. Your task is\n",
        "        # to update the `propagate()` function in order to pass `pos`\n",
        "        # to the `message()` function along with the other arguments.\n",
        "        #\n",
        "        out = self.propagate(edge_index, h=h, edge_attr=edge_attr, pos=pos)\n",
        "        return out\n",
        "        # ==========================================\n",
        "\n",
        "    # ============ YOUR CODE HERE ==============\n",
        "    # Write a custom `message()` function that takes as arguments the\n",
        "    # source and destination node features, node coordinates, and `edge_attr`.\n",
        "    # Incorporate the coordinates `pos` into the message computation such\n",
        "    # that the messages are invariant to rotations and translations.\n",
        "    # This will ensure that the overall layer is also invariant.\n",
        "    #\n",
        "    def message(self, h_i, h_j, edge_attr, pos_i, pos_j):\n",
        "      \"\"\"The `message()` function constructs messages from source nodes j\n",
        "        to destination nodes i for each edge (j, i) in `edge_index`.\n",
        "\n",
        "        Args:\n",
        "            ...\n",
        "\n",
        "        Returns:\n",
        "            ...\n",
        "      \"\"\"\n",
        "      # print(h_i.shape, h_j.shape, edge_attr.shape, pos_i.shape, pos_j.shape)\n",
        "      msg = torch.cat([h_i, h_j, edge_attr, torch.norm(pos_i - pos_j, dim=-1).unsqueeze(-1)], dim=-1)\n",
        "      # print(msg.shape)\n",
        "      return self.mlp_msg(msg)\n",
        "    # ==========================================\n",
        "\n",
        "    def aggregate(self, inputs, index):\n",
        "        \"\"\"The `aggregate` function aggregates the messages from neighboring nodes,\n",
        "        according to the chosen aggregation function ('sum' by default).\n",
        "\n",
        "        Args:\n",
        "            inputs: (e, d) - messages `m_ji` from source to destination nodes\n",
        "            index: (e, 1) - list of destination nodes for each edge/message in `input`\n",
        "\n",
        "        Returns:\n",
        "            aggr_out: (n, d) - aggregated messages `m_i`\n",
        "        \"\"\"\n",
        "        return scatter(inputs, index, dim=self.node_dim, reduce=self.aggr)\n",
        "\n",
        "    def update(self, aggr_out, h):\n",
        "        \"\"\"The `update()` function computes the final node features by combining the\n",
        "        aggregated messages with the initial node features.\n",
        "\n",
        "        Args:\n",
        "            aggr_out: (n, d) - aggregated messages `m_i`\n",
        "            h: (n, d) - initial node features\n",
        "\n",
        "        Returns:\n",
        "            upd_out: (n, d) - updated node features passed through MLP `\\phi`\n",
        "        \"\"\"\n",
        "        upd_out = torch.cat([h, aggr_out], dim=-1)\n",
        "        return self.mlp_upd(upd_out)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return (f'{self.__class__.__name__}(emb_dim={self.emb_dim}, aggr={self.aggr})')\n",
        "\n",
        "\n",
        "class InvariantMPNNModel(MPNNModel):\n",
        "    def __init__(self, num_layers=4, emb_dim=64, in_dim=11, edge_dim=4, out_dim=1):\n",
        "        \"\"\"Message Passing Neural Network model for graph property prediction\n",
        "\n",
        "        This model uses both node features and coordinates as inputs, and\n",
        "        is invariant to 3D rotations and translations.\n",
        "\n",
        "        Args:\n",
        "            num_layers: (int) - number of message passing layers `L`\n",
        "            emb_dim: (int) - hidden dimension `d`\n",
        "            in_dim: (int) - initial node feature dimension `d_n`\n",
        "            edge_dim: (int) - edge feature dimension `d_e`\n",
        "            out_dim: (int) - output dimension (fixed to 1)\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # Linear projection for initial node features\n",
        "        # dim: d_n -> d\n",
        "        self.lin_in = Linear(in_dim, emb_dim)\n",
        "\n",
        "        # Stack of invariant MPNN layers\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for layer in range(num_layers):\n",
        "            self.convs.append(InvariantMPNNLayer(emb_dim, edge_dim, aggr='add'))\n",
        "\n",
        "        # Global pooling/readout function `R` (mean pooling)\n",
        "        # PyG handles the underlying logic via `global_mean_pool()`\n",
        "        self.pool = global_mean_pool\n",
        "\n",
        "        # Linear prediction head\n",
        "        # dim: d -> out_dim\n",
        "        self.lin_pred = Linear(emb_dim, out_dim)\n",
        "\n",
        "    def forward(self, data):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data: (PyG.Data) - batch of PyG graphs\n",
        "\n",
        "        Returns:\n",
        "            out: (batch_size, out_dim) - prediction for each graph\n",
        "        \"\"\"\n",
        "        h = self.lin_in(data.x) # (n, d_n) -> (n, d)\n",
        "\n",
        "        for conv in self.convs:\n",
        "            h = h + conv(h, data.pos, data.edge_index, data.edge_attr) # (n, d) -> (n, d)\n",
        "            # Note that we add a residual connection after each MPNN layer\n",
        "\n",
        "        h_graph = self.pool(h, data.batch) # (n, d) -> (batch_size, d)\n",
        "\n",
        "        out = self.lin_pred(h_graph) # (batch_size, d) -> (batch_size, 1)\n",
        "\n",
        "        return out.view(-1)"
      ],
      "metadata": {
        "id": "3LCsBeLkXwet"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m3PZ3ZGJdWMd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}