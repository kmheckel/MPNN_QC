{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kmheckel/MPNN_QC/blob/main/GGNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Things to do: Data loading onto GPU, Tuning learning rate, make networks and settings as general as possible, use validation data set, showable loss improvement, standardise the input data\n",
        "### Preliminaries and loading data"
      ],
      "metadata": {
        "id": "iixb2LDDBoXo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HzBEa4pVtZ9C",
        "outputId": "65fda259-9714-4be8-c101-064619692995",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correct version of torch detected. You are running on a machine with GPU.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "#@title [RUN] Sanity check torch version and GPU runtime\n",
        "\n",
        "import torch\n",
        "assert torch.cuda.is_available(), \"WARNING! You are running on a non-GPU instance. For this practical a GPU is highly recommended.\"\n",
        "REQUIRED_VERSION = \"2.1.0+cu121\"\n",
        "TORCH_VERSION = torch.__version__\n",
        "CUDA_VERSION = TORCH_VERSION.split(\"+\")\n",
        "\n",
        "if TORCH_VERSION != REQUIRED_VERSION:\n",
        "  print(f\"Detected torch version {TORCH_VERSION}, but notebook was created for {REQUIRED_VERSION}\")\n",
        "  print(f\"Attempting installation of {REQUIRED_VERSION}\")\n",
        "  !pip install torch==2.1.0+cu121\n",
        "print(\"Correct version of torch detected. You are running on a machine with GPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Install required python libraries\n",
        "import os\n",
        "\n",
        "# Install PyTorch Geometric and other libraries\n",
        "if 'IS_GRADESCOPE_ENV' not in os.environ:\n",
        "    print(\"Installing PyTorch Geometric\")\n",
        "    !pip install -q torch-scatter -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-sparse -f https://data.pyg.org/whl/torch-2.1.0+cu121.html\n",
        "    !pip install -q torch-geometric\n",
        "    print(\"Installing other libraries\")\n",
        "    !pip install -q rdkit-pypi==2021.9.4\n",
        "    !pip install -q py3Dmol==1.8.0\n",
        "    !pip install networkx\n",
        "    !pip install mycolorpy\n",
        "    !pip install colorama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QgDyw0ltu7o",
        "outputId": "5b5e1dd3-8083-42dd-8056-1e5dcb26726e",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing PyTorch Geometric\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling other libraries\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Collecting mycolorpy\n",
            "  Downloading mycolorpy-1.5.1.tar.gz (2.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mycolorpy) (1.25.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mycolorpy) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mycolorpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mycolorpy) (1.16.0)\n",
            "Building wheels for collected packages: mycolorpy\n",
            "  Building wheel for mycolorpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mycolorpy: filename=mycolorpy-1.5.1-py3-none-any.whl size=3851 sha256=767f62d29c70ae37b7f6ad185e4961c282c17375ae716271270f01c09cfa284c\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/1d/04/f8bfb8b04e3daba330b3f377c041b89304271ff98fb6704946\n",
            "Successfully built mycolorpy\n",
            "Installing collected packages: mycolorpy\n",
            "Successfully installed mycolorpy-1.5.1\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Import python modules\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "import random\n",
        "import itertools\n",
        "from datetime import datetime\n",
        "from typing import Mapping, Tuple, Sequence, List\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "from scipy.stats import ortho_group\n",
        "from scipy.linalg import block_diag\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.nn import Embedding, Linear, ReLU, BatchNorm1d, Module, ModuleList, Sequential\n",
        "\n",
        "import torch_geometric\n",
        "from torch_geometric.data import Data, Batch\n",
        "from torch_geometric.loader import DataLoader\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.utils import remove_self_loops, to_dense_adj, dense_to_sparse\n",
        "from torch_geometric.datasets import Planetoid, QM9\n",
        "from torch_geometric.nn import MessagePassing, global_mean_pool\n",
        "from torch_scatter import scatter, scatter_mean, scatter_max, scatter_sum\n",
        "\n",
        "import rdkit.Chem as Chem\n",
        "from rdkit.Geometry.rdGeometry import Point3D\n",
        "from rdkit.Chem import QED, Crippen, rdMolDescriptors, rdmolops\n",
        "from rdkit.Chem.Draw import IPythonConsole\n",
        "\n",
        "import py3Dmol\n",
        "from rdkit.Chem import AllChem\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mycolorpy import colorlist as mcp\n",
        "import matplotlib.cm as cm\n",
        "import colorama\n",
        "\n",
        "from google.colab import files\n",
        "from IPython.display import HTML\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"All imports succeeded.\")\n",
        "print(\"Python version {}\".format(sys.version))\n",
        "print(\"PyTorch version {}\".format(torch.__version__))\n",
        "print(\"PyG version {}\".format(torch_geometric.__version__))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_UDZ_6LtzGU",
        "outputId": "968fdf2b-31b6-44e0-de37-9c285d24ae65",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All imports succeeded.\n",
            "Python version 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "PyTorch version 2.1.0+cu121\n",
            "PyG version 2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Set random seed for deterministic results\n",
        "\n",
        "def seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed(0)\n",
        "print(\"All seeds set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2oQB7rCDt42f",
        "outputId": "c210508b-9f16-4cc4-edc0-b62ac066475a",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All seeds set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Helper functions for data preparation\n",
        "\n",
        "class SetTarget:\n",
        "    \"\"\"\n",
        "    This transform modifies the labels vector per data sample to only keep\n",
        "    the label for a specific target (there are 19 targets in QM9).\n",
        "\n",
        "    Note: for this practical, we have hardcoded the target to be target #0,\n",
        "    i.e. the electric dipole moment of a drug-like molecule.\n",
        "    (https://en.wikipedia.org/wiki/Electric_dipole_moment)\n",
        "    \"\"\"\n",
        "    def __init__(self, target=0):\n",
        "      self.target = target\n",
        "    def __call__(self, data):\n",
        "        data.y = data.y[:, self.target]\n",
        "        return data\n",
        "\n",
        "\n",
        "class CompleteGraph:\n",
        "    \"\"\"\n",
        "    This transform adds all pairwise edges into the edge index per data sample,\n",
        "    then removes self loops, i.e. it builds a fully connected or complete graph\n",
        "    \"\"\"\n",
        "    def __call__(self, input):\n",
        "        data = input.clone()\n",
        "        device = data.edge_index.device\n",
        "\n",
        "        row = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "        col = torch.arange(data.num_nodes, dtype=torch.long, device=device)\n",
        "\n",
        "        row = row.view(-1, 1).repeat(1, data.num_nodes).view(-1)\n",
        "        col = col.repeat(data.num_nodes)\n",
        "        edge_index = torch.stack([row, col], dim=0)\n",
        "\n",
        "        edge_attr = None\n",
        "        if data.edge_attr is not None:\n",
        "            idx = data.edge_index[0] * data.num_nodes + data.edge_index[1]\n",
        "            size = list(data.edge_attr.size())\n",
        "            size[0] = data.num_nodes * data.num_nodes\n",
        "            edge_attr = data.edge_attr.new_zeros(size)\n",
        "            edge_attr[idx] = data.edge_attr\n",
        "\n",
        "        edge_index, edge_attr = remove_self_loops(edge_index, edge_attr)\n",
        "        data.edge_attr = edge_attr\n",
        "        data.edge_index = edge_index\n",
        "\n",
        "        return data\n",
        "\n",
        "print(\"Helper functions loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D53xaR6SuPVb",
        "outputId": "d0ca1711-0c91-497c-84e2-5b6aca73111c",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title [RUN] Helper functions for plots and visualisations\n",
        "\n",
        "\n",
        "def draw_one_graph(ax, edges, label=None, node_emb=None, layout=None, special_color=False):\n",
        "    \"\"\"draw a graph with networkx based on adjacency matrix (edges)\n",
        "    graph labels could be displayed as a title for each graph\n",
        "    node_emb could be displayed in colors\n",
        "    \"\"\"\n",
        "    graph = nx.Graph()\n",
        "    edges = zip(edges[0], edges[1])\n",
        "    graph.add_edges_from(edges)\n",
        "    node_pos = layout(graph)\n",
        "    #add colors according to node embeding\n",
        "    if (node_emb is not None) or special_color:\n",
        "        color_map = []\n",
        "        node_list = [node[0] for node in graph.nodes(data = True)]\n",
        "        for i,node in enumerate(node_list):\n",
        "            #just ignore this branch\n",
        "            if special_color:\n",
        "                if len(node_list) == 3:\n",
        "                    crt_color = (1,0,0)\n",
        "                elif len(node_list) == 5:\n",
        "                    crt_color = (0,1,0)\n",
        "                elif len(node_list) == 4:\n",
        "                    crt_color = (1,1,0)\n",
        "                else:\n",
        "                  special_list = [(1,0,0)] * 3 + [(0,1,0)] * 5 + [(1,1,0)] * 4\n",
        "                  crt_color = special_list[i]\n",
        "            else:\n",
        "                crt_node_emb = node_emb[node]\n",
        "                #map float number (node embeding) to a color\n",
        "                crt_color = cm.gist_rainbow(crt_node_emb, bytes=True)\n",
        "                crt_color = (crt_color[0]/255.0, crt_color[1]/255.0, crt_color[2]/255.0, crt_color[3]/255.0)\n",
        "            color_map.append(crt_color)\n",
        "\n",
        "        nx.draw_networkx_nodes(graph,node_pos, node_color=color_map,\n",
        "                        nodelist = node_list, ax=ax)\n",
        "        nx.draw_networkx_edges(graph, node_pos, ax=ax)\n",
        "        nx.draw_networkx_labels(graph,node_pos, ax=ax)\n",
        "    else:\n",
        "        nx.draw_networkx(graph, node_pos, ax=ax)\n",
        "\n",
        "\n",
        "def gallery(graphs, labels=None, node_emb=None, special_color=False, max_graphs=4, max_fig_size=(40, 10), layout=nx.layout.kamada_kawai_layout):\n",
        "    ''' Draw multiple graphs as a gallery\n",
        "    Args:\n",
        "      graphs: torch_geometrics.dataset object/ List of Graph objects\n",
        "      labels: num_graphs\n",
        "      node_emb: num_graphs* [num_nodes x num_ch]\n",
        "      max_graphs: maximum graphs display\n",
        "    '''\n",
        "    num_graphs = min(len(graphs), max_graphs)\n",
        "    ff, axes = plt.subplots(1, num_graphs,\n",
        "                            figsize=max_fig_size,\n",
        "                            subplot_kw={'xticks': [], 'yticks': []})\n",
        "    if num_graphs == 1:\n",
        "        axes = [axes]\n",
        "    if node_emb is None:\n",
        "        node_emb = num_graphs*[None]\n",
        "    if labels is None:\n",
        "        labels = num_graphs * [\" \"]\n",
        "\n",
        "\n",
        "    for i in range(num_graphs):\n",
        "        draw_one_graph(axes[i], graphs[i].edge_index.numpy(), labels[i], node_emb[i], layout, special_color)\n",
        "        if labels[i] != \" \":\n",
        "            axes[i].set_title(f\"Target: {labels[i]}\", fontsize=28)\n",
        "        axes[i].set_axis_off()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def hash_node_embedings(node_emb):\n",
        "  \"\"\" Hash the tensor representing nodes' features\n",
        "  to a number in [0,1] used to represent a color\n",
        "\n",
        "  Args:\n",
        "    node_emb: list of num_graphs arrays, each of dim (num_nodes x num_feats)\n",
        "  Returns:\n",
        "    list of num_graphs arrays in [0,1], each of dim (num_nodes)\n",
        "  \"\"\"\n",
        "  chunk_size_graph = [x.shape[0] for x in node_emb]\n",
        "  start_idx_graph = [0] + list(itertools.accumulate(chunk_size_graph))[:-1]\n",
        "\n",
        "  node_emb_flatten = np.concatenate(node_emb).mean(-1)\n",
        "\n",
        "  min_emb = node_emb_flatten.min()\n",
        "  max_emb = node_emb_flatten.max()\n",
        "  node_emb_flatten = (node_emb_flatten-min_emb)/(max_emb-min_emb)\n",
        "\n",
        "  #split in graphs again according to (start_idx_graph, chunk_size_graph)\n",
        "  node_emb_hashed = [node_emb_flatten[i:i+l] for (i,l) in zip(start_idx_graph, chunk_size_graph)]\n",
        "  return node_emb_hashed\n",
        "\n",
        "\n",
        "def update_stats(training_stats, epoch_stats):\n",
        "    \"\"\" Store metrics along the training\n",
        "    Args:\n",
        "      epoch_stats: dict containg metrics about one epoch\n",
        "      training_stats: dict containing lists of metrics along training\n",
        "    Returns:\n",
        "      updated training_stats\n",
        "    \"\"\"\n",
        "    if training_stats is None:\n",
        "        training_stats = {}\n",
        "        for key in epoch_stats.keys():\n",
        "            training_stats[key] = []\n",
        "    for key,val in epoch_stats.items():\n",
        "        training_stats[key].append(val)\n",
        "    return training_stats\n",
        "\n",
        "\n",
        "def plot_stats(training_stats, figsize=(5, 5), name=\"\"):\n",
        "    \"\"\" Create one plot for each metric stored in training_stats\n",
        "    \"\"\"\n",
        "    stats_names = [key[6:] for key in training_stats.keys() if key.startswith('train_')]\n",
        "    f, ax = plt.subplots(len(stats_names), 1, figsize=figsize)\n",
        "    if len(stats_names)==1:\n",
        "        ax = np.array([ax])\n",
        "    for key, axx in zip(stats_names, ax.reshape(-1,)):\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'train_{key}'],\n",
        "            label=f\"Training {key}\")\n",
        "        axx.plot(\n",
        "            training_stats['epoch'],\n",
        "            training_stats[f'val_{key}'],\n",
        "            label=f\"Validation {key}\")\n",
        "        axx.set_xlabel(\"Training epoch\")\n",
        "        axx.set_ylabel(key)\n",
        "        axx.legend()\n",
        "    plt.title(name)\n",
        "\n",
        "\n",
        "def get_color_coded_str(i, color):\n",
        "    return \"\\033[3{}m{}\\033[0m\".format(int(color), int(i))\n",
        "\n",
        "\n",
        "def print_color_numpy(map, list_graphs):\n",
        "    \"\"\" print matrix map in color according to list_graphs\n",
        "    \"\"\"\n",
        "    list_blocks = []\n",
        "    for i,graph in enumerate(list_graphs):\n",
        "        block_i = (i+1)*np.ones((graph.num_nodes,graph.num_nodes))\n",
        "        list_blocks += [block_i]\n",
        "    block_color = block_diag(*list_blocks)\n",
        "\n",
        "    map_modified = np.vectorize(get_color_coded_str)(map, block_color)\n",
        "    print(\"\\n\".join([\" \".join([\"{}\"]*map.shape[0])]*map.shape[1]).format(*[x for y in map_modified.tolist() for x in y]))\n",
        "\n",
        "\n",
        "#############################################\n",
        "# Visualization helpers for molecular graphs\n",
        "#############################################\n",
        "\n",
        "allowable_atoms = [\n",
        "    \"H\",\n",
        "    \"C\",\n",
        "    \"N\",\n",
        "    \"O\",\n",
        "    \"F\",\n",
        "    \"C\",\n",
        "    \"Cl\",\n",
        "    \"Br\",\n",
        "    \"I\",\n",
        "    \"H\",\n",
        "    \"Unknown\",\n",
        "]\n",
        "\n",
        "def to_atom(t):\n",
        "    try:\n",
        "        return allowable_atoms[int(t.argmax())]\n",
        "    except:\n",
        "        return \"C\"\n",
        "\n",
        "\n",
        "def to_bond_index(t):\n",
        "    t_s = t.squeeze()\n",
        "    return [1, 2, 3, 4][\n",
        "        int(\n",
        "            torch.dot(\n",
        "                t_s,\n",
        "                torch.tensor(\n",
        "                    range(t_s.size()[0]), dtype=torch.float, device=t.device\n",
        "                ),\n",
        "            ).item()\n",
        "        )\n",
        "    ]\n",
        "\n",
        "def to_rdkit(data, device=None):\n",
        "    has_pos = False\n",
        "    node_list = []\n",
        "    for i in range(data.x.size()[0]):\n",
        "        node_list.append(to_atom(data.x[i][:5]))\n",
        "\n",
        "    # create empty editable mol object\n",
        "    mol = Chem.RWMol()\n",
        "    # add atoms to mol and keep track of index\n",
        "    node_to_idx = {}\n",
        "    invalid_idx = set([])\n",
        "    for i in range(len(node_list)):\n",
        "        if node_list[i] == \"Stop\" or node_list[i] == \"H\":\n",
        "            invalid_idx.add(i)\n",
        "            continue\n",
        "        a = Chem.Atom(node_list[i])\n",
        "        molIdx = mol.AddAtom(a)\n",
        "        node_to_idx[i] = molIdx\n",
        "\n",
        "    added_bonds = set([])\n",
        "    for i in range(0, data.edge_index.size()[1]):\n",
        "        ix = data.edge_index[0][i].item()\n",
        "        iy = data.edge_index[1][i].item()\n",
        "        bond = to_bond_index(data.edge_attr[i])  # <font color='red'>TODO</font> fix this\n",
        "        # bond = 1\n",
        "        # add bonds between adjacent atoms\n",
        "\n",
        "        if data.edge_attr[i].sum() == 0:\n",
        "          continue\n",
        "\n",
        "        if (\n",
        "            (str((ix, iy)) in added_bonds)\n",
        "            or (str((iy, ix)) in added_bonds)\n",
        "            or (iy in invalid_idx or ix in invalid_idx)\n",
        "        ):\n",
        "            continue\n",
        "        # add relevant bond type (there are many more of these)\n",
        "\n",
        "        if bond == 0:\n",
        "            continue\n",
        "        elif bond == 1:\n",
        "            bond_type = Chem.rdchem.BondType.SINGLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 2:\n",
        "            bond_type = Chem.rdchem.BondType.DOUBLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 3:\n",
        "            bond_type = Chem.rdchem.BondType.TRIPLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "        elif bond == 4:\n",
        "            bond_type = Chem.rdchem.BondType.SINGLE\n",
        "            mol.AddBond(node_to_idx[ix], node_to_idx[iy], bond_type)\n",
        "\n",
        "        added_bonds.add(str((ix, iy)))\n",
        "\n",
        "    if has_pos:\n",
        "        conf = Chem.Conformer(mol.GetNumAtoms())\n",
        "        for i in range(data.pos.size(0)):\n",
        "            if i in invalid_idx:\n",
        "                continue\n",
        "            p = Point3D(\n",
        "                data.pos[i][0].item(),\n",
        "                data.pos[i][1].item(),\n",
        "                data.pos[i][2].item(),\n",
        "            )\n",
        "            conf.SetAtomPosition(node_to_idx[i], p)\n",
        "        conf.SetId(0)\n",
        "        mol.AddConformer(conf)\n",
        "\n",
        "    # Convert RWMol to Mol object\n",
        "    mol = mol.GetMol()\n",
        "    mol_frags = rdmolops.GetMolFrags(mol, asMols=True, sanitizeFrags=False)\n",
        "    largest_mol = max(mol_frags, default=mol, key=lambda m: m.GetNumAtoms())\n",
        "    return largest_mol\n",
        "\n",
        "\n",
        "def MolTo3DView(mol, size=(300, 300), style=\"stick\", surface=False, opacity=0.5):\n",
        "    \"\"\"Draw molecule in 3D\n",
        "\n",
        "    Args:\n",
        "    ----\n",
        "        mol: rdMol, molecule to show\n",
        "        size: tuple(int, int), canvas size\n",
        "        style: str, type of drawing molecule\n",
        "               style can be 'line', 'stick', 'sphere', 'carton'\n",
        "        surface, bool, display SAS\n",
        "        opacity, float, opacity of surface, range 0.0-1.0\n",
        "    Return:\n",
        "    ----\n",
        "        viewer: py3Dmol.view, a class for constructing embedded 3Dmol.js views in ipython notebooks.\n",
        "    \"\"\"\n",
        "    assert style in ('line', 'stick', 'sphere', 'carton')\n",
        "\n",
        "    mol = Chem.AddHs(mol)\n",
        "    AllChem.EmbedMolecule(mol)\n",
        "    AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
        "    mblock = Chem.MolToMolBlock(mol)\n",
        "    viewer = py3Dmol.view(width=size[0], height=size[1])\n",
        "    viewer.addModel(mblock, 'mol')\n",
        "    viewer.setStyle({style:{}})\n",
        "    if surface:\n",
        "        viewer.addSurface(py3Dmol.SAS, {'opacity': opacity})\n",
        "    viewer.zoomTo()\n",
        "    return viewer\n",
        "\n",
        "def smi2conf(smiles):\n",
        "    '''Convert SMILES to rdkit.Mol with 3D coordinates'''\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    if mol is not None:\n",
        "        mol = Chem.AddHs(mol)\n",
        "        AllChem.EmbedMolecule(mol)\n",
        "        AllChem.MMFFOptimizeMolecule(mol, maxIters=200)\n",
        "        return mol\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "print(\"Helper functions loaded.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdAPY5jDuW3L",
        "outputId": "2df8e28f-7e75-4ed5-db35-8e79d6cb69d9",
        "cellView": "form"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Helper functions loaded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title [RUN] Set random seed for deterministic results\n",
        "\n",
        "def seed(seed=0):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed(0)\n",
        "print(\"All seeds set.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baHmJHyNSoqW",
        "outputId": "bde2f681-bb89-4aed-8b56-bc82f3d02a53"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All seeds set.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RESULTS = {}\n",
        "DF_RESULTS = pd.DataFrame(columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])"
      ],
      "metadata": {
        "id": "AfykpUREStOZ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Data"
      ],
      "metadata": {
        "id": "rabnXDUvS8Zx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = QM9(root='/tmp/QM9')\n",
        "target = 0\n",
        "dataset.data.y = dataset.data.y[:, target]\n",
        "# Normalize targets per data sample to mean = 0 and std = 1.\n",
        "mean = dataset.data.y.mean(dim=0, keepdim=True)\n",
        "std = dataset.data.y.std(dim=0, keepdim=True)\n",
        "dataset.data.y = (dataset.data.y - mean) / std\n",
        "mean, std = mean.item(), std.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bjnEf5QS_CV",
        "outputId": "2b1ae23c-8516-480b-950e-bf9adfbc6ad5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://deepchemdata.s3-us-west-1.amazonaws.com/datasets/molnet_publish/qm9.zip\n",
            "Extracting /tmp/QM9/raw/qm9.zip\n",
            "Downloading https://ndownloader.figshare.com/files/3195404\n",
            "Processing...\n",
            "100%|██████████| 133885/133885 [02:16<00:00, 981.78it/s]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO USE FULL DATASET:\n",
        "# test_dataset = dataset[:10000]\n",
        "# val_dataset = dataset[10000:20000]\n",
        "# train_dataset = dataset[20000:]\n",
        "\n",
        "train_dataset = dataset[:1000]\n",
        "val_dataset = dataset[1000:2000]\n",
        "test_dataset = dataset[2000:3000]\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "print(f\"Created dataset splits with {len(train_dataset)} training, {len(val_dataset)} validation, {len(test_dataset)} test samples.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a479-SedTHNR",
        "outputId": "6ba5ae9b-deee-4b05-9a39-73748aee79ec"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created dataset splits with 1000 training, 1000 validation, 1000 test samples.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementing GGNNs"
      ],
      "metadata": {
        "id": "KoTPUWws_d4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load necessary packages\n",
        "import torch\n",
        "from torch_geometric.nn import GatedGraphConv, global_mean_pool, global_add_pool, GRUAggregation\n",
        "#from torch_geometric.datasets import QM9 (already loaded QM9)\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.nn import Linear\n",
        "import torch.nn.functional as F"
      ],
      "metadata": {
        "id": "9ErB3_tSLfKP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, optimizer, device):\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(data)\n",
        "        loss = F.mse_loss(y_pred, data.y)\n",
        "        loss.backward()\n",
        "        loss_all += loss.item() * data.num_graphs\n",
        "        optimizer.step()\n",
        "    return loss_all / len(train_loader.dataset)"
      ],
      "metadata": {
        "id": "scRV-Uo9KlW_"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(model, loader, device):\n",
        "    model.eval()\n",
        "    error = 0\n",
        "\n",
        "    for data in loader:\n",
        "        data = data.to(device)\n",
        "        with torch.no_grad():\n",
        "            y_pred = model(data)\n",
        "            # Mean Absolute Error using std (computed when preparing data)\n",
        "            error += (y_pred * std - data.y * std).abs().sum().item()\n",
        "    return error / len(loader.dataset)"
      ],
      "metadata": {
        "id": "MxPenzAuKn-N"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(model, model_name, train_loader, val_loader, test_loader, n_epochs=100, patience=float('inf')):\n",
        "    print(f\"Running experiment for {model_name}, training on {len(train_loader.dataset)} samples for {n_epochs} epochs.\")\n",
        "\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f'Training on {device}.')\n",
        "\n",
        "    print(\"\\nModel architecture:\")\n",
        "    print(model)\n",
        "    total_param = 0\n",
        "    for param in model.parameters():\n",
        "        total_param += np.prod(list(param.data.size()))\n",
        "    print(f'Total parameters: {total_param}')\n",
        "    model = model.to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.9, patience=5, min_lr=0.00001)\n",
        "\n",
        "    print(\"\\nStart training:\")\n",
        "    best_val_error = float('inf')\n",
        "    perf_per_epoch = []\n",
        "    t = time.time()\n",
        "    patience_counter = 0\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
        "        loss = train(model, train_loader, optimizer, device)\n",
        "        val_error = eval(model, val_loader, device)\n",
        "\n",
        "        if val_error < best_val_error:\n",
        "            best_val_error = val_error\n",
        "            test_error = eval(model, test_loader, device)  # Evaluate model on test set if validation metric improves\n",
        "            patience_counter = 0  # Reset patience counter\n",
        "\n",
        "            # Generate the current date string\n",
        "            current_date = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
        "            model_save_path = f'models/{current_date}/{model_name}_{model.num_layers}layers_{type(model.aggr).__name__}_aggr.pt'\n",
        "\n",
        "            # Create directory if it does not exist\n",
        "            os.makedirs(os.path.dirname(model_save_path), exist_ok=True)\n",
        "\n",
        "            # Save the model\n",
        "            torch.save(model.state_dict(), model_save_path)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch: {epoch:03d}, LR: {lr:5f}, Loss: {loss:.7f}, '\n",
        "                  f'Val MAE: {val_error:.7f}, Test MAE: {test_error:.7f}')\n",
        "\n",
        "        scheduler.step(val_error)\n",
        "        perf_per_epoch.append((test_error, val_error, epoch, model_name))\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Stopping early due to no improvement in validation loss for {patience} epochs.\")\n",
        "            break\n",
        "\n",
        "    t = time.time() - t\n",
        "    train_time = t / 60\n",
        "    print(f\"\\nDone! Training took {train_time:.2f} mins. Best validation MAE: {best_val_error:.7f}, corresponding test MAE: {test_error:.7f}.\")\n",
        "\n",
        "    return best_val_error, test_error, train_time, perf_per_epoch"
      ],
      "metadata": {
        "id": "1H1hXr0aL0oj"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class GGNNPyG(torch.nn.Module):\n",
        "#   def __init__(self, num_node_features, num_classes, num_layers):\n",
        "#     super(GGNNPyG, self).__init__()\n",
        "#     self.ggnn = GatedGraphConv(out_channels=num_node_features, num_layers=3)\n",
        "#     self.lin = Linear(num_node_features, num_classes)\n",
        "#     self.aggr = GRUAggregation(in_channels=num_node_features)\n",
        "\n",
        "#   def forward(self, data):\n",
        "#     x, edge_index = data.x, data.edge_index\n",
        "#     x = self.ggnn(x, edge_index)\n",
        "#     #x = GRUAggregation()\n",
        "#     #x = global_add_pool(x, data.batch) # using add pooling to aggregate the features\n",
        "#     x = F.relu(self.lin(x))\n",
        "#     return x.view(-1)"
      ],
      "metadata": {
        "id": "EvSgeoUf_Z_b"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCNConv, GINConv, global_mean_pool, GRUAggregation, Set2Set\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.utils import sort_edge_index\n",
        "\n",
        "class CustomGGNN(torch.nn.Module):\n",
        "    def __init__(self, input_channels, hidden_channels, output_channels=1, num_layers=4, T=4):\n",
        "        super(CustomGGNN, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.first_layer = Linear(input_channels, hidden_channels)\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        # Hidden layers\n",
        "        for _ in range(num_layers):\n",
        "            self.convs.append(GatedGraphConv(hidden_channels, num_layers))\n",
        "\n",
        "        # if not using set2set\n",
        "        # self.out = torch.nn.Linear(hidden_channels, output_channels)\n",
        "\n",
        "        self.out = torch.nn.Linear(hidden_channels, output_channels)\n",
        "        self.aggr = GRUAggregation(in_channels=hidden_channels, out_channels=hidden_channels)\n",
        "\n",
        "    # def forward(self, data):\n",
        "    #     x = self.first_layer(data.x)\n",
        "    #     # Sort edge_index by destination nodes\n",
        "    #     data = data.sort(sort_by_row=False)\n",
        "    #     for conv in self.convs:\n",
        "    #       # Sort both x and edge_index\n",
        "    #       x, sorted_edge_index = data.x, data.edge_index\n",
        "    #       x = x + F.relu(conv(x, sorted_edge_index))\n",
        "\n",
        "    #     x = self.aggr(x, sorted_edge_index)\n",
        "    #     x = self.out(x)\n",
        "    #     return x.view(-1)\n",
        "\n",
        "\n",
        "    def forward(self, data):\n",
        "        x = self.first_layer(data.x)\n",
        "        for conv in self.convs:\n",
        "            x = x + F.relu(conv(x, data.edge_index))\n",
        "        # x = global_mean_pool(x, data.batch)\n",
        "        x = self.aggr(x, data.batch)\n",
        "        x = self.out(x)\n",
        "        return x.view(-1)\n",
        ""
      ],
      "metadata": {
        "id": "XB5mFE61Pdof"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 5\n",
        "\n",
        "model = CustomGGNN(dataset.num_node_features, hidden_channels=64, num_layers=num_layers)\n",
        "model_name = type(model).__name__\n",
        "best_val_error, test_error, train_time, perf_per_epoch = run_experiment(\n",
        "    model,\n",
        "    model_name,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    test_loader,\n",
        "    n_epochs=100\n",
        ")\n",
        "RESULTS[model_name] = (best_val_error, test_error, train_time)\n",
        "df_temp = pd.DataFrame(perf_per_epoch, columns=[\"Test MAE\", \"Val MAE\", \"Epoch\", \"Model\"])\n",
        "DF_RESULTS = DF_RESULTS.append(df_temp, ignore_index=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDOiFJeNQYTq",
        "outputId": "1a000822-4aba-408b-85ff-6e00c39f840f"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running experiment for CustomGGNN, training on 1000 samples for 100 epochs.\n",
            "Training on cuda.\n",
            "\n",
            "Model architecture:\n",
            "CustomGGNN(\n",
            "  (first_layer): Linear(in_features=11, out_features=64, bias=True)\n",
            "  (convs): ModuleList(\n",
            "    (0-4): 5 x GatedGraphConv(64, num_layers=5)\n",
            "  )\n",
            "  (out): Linear(in_features=64, out_features=1, bias=True)\n",
            "  (aggr): GRUAggregation(64, 64)\n",
            ")\n",
            "Total parameters: 252993\n",
            "\n",
            "Start training:\n",
            "Epoch: 010, LR: 0.001000, Loss: 0.4867313, Val MAE: 0.8365066, Test MAE: 0.6937281\n",
            "Epoch: 020, LR: 0.001000, Loss: 0.3610062, Val MAE: 0.7447105, Test MAE: 0.5947344\n",
            "Epoch: 030, LR: 0.000900, Loss: 0.2099805, Val MAE: 0.7077724, Test MAE: 0.5669046\n",
            "Epoch: 040, LR: 0.000900, Loss: 0.1406001, Val MAE: 0.6699416, Test MAE: 0.5650703\n",
            "Epoch: 050, LR: 0.000900, Loss: 0.0859286, Val MAE: 0.6578665, Test MAE: 0.5491527\n",
            "Epoch: 060, LR: 0.000900, Loss: 0.0710177, Val MAE: 0.6418520, Test MAE: 0.5418465\n",
            "Epoch: 070, LR: 0.000810, Loss: 0.0377436, Val MAE: 0.6273726, Test MAE: 0.5454626\n",
            "Epoch: 080, LR: 0.000729, Loss: 0.0242757, Val MAE: 0.6209833, Test MAE: 0.5338485\n",
            "Epoch: 090, LR: 0.000590, Loss: 0.0203605, Val MAE: 0.6223581, Test MAE: 0.5407429\n",
            "Epoch: 100, LR: 0.000590, Loss: 0.0147024, Val MAE: 0.6090224, Test MAE: 0.5412304\n",
            "\n",
            "Done! Training took 2.00 mins. Best validation MAE: 0.6070651, corresponding test MAE: 0.5412304.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "RESULTS"
      ],
      "metadata": {
        "id": "eY1rggrTMbA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3520c5-1561-4075-8e7d-d6dbb71b1ecd"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'CustomGGNN': (0.6070651209354401, 0.5412304062843323, 1.9989202539126079)}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    }
  ]
}